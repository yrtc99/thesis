{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af97ee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36173da",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    \n",
    "]\n",
    "\n",
    "roc_auc_datasets = [    ]\n",
    "\n",
    "models = [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3b90300",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c543a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model_name = model.replace('-', '_').replace('+', '_')\n",
    "    results = []\n",
    "    for dataset in datasets:\n",
    "        val_metrics = []\n",
    "        metric_name = 'ROC AUC' if dataset in roc_auc_datasets else 'accuracy'\n",
    "        for num_layers in range(1, 6):\n",
    "            filename = f'../experiments/{dataset}/{model_name}_l{num_layers}_01/metrics.yaml'\n",
    "            if os.path.exists(filename):\n",
    "                with open(filename) as file:\n",
    "                    metrics = yaml.safe_load(file)\n",
    "\n",
    "                val_metric_mean = metrics[f'val {metric_name} mean']\n",
    "                val_metrics.append(val_metric_mean)\n",
    "        \n",
    "        if not val_metrics:\n",
    "            string = ''\n",
    "        else:\n",
    "            best_num_layers = np.argmax(val_metrics) + 1\n",
    "            filename = f'../experiments/{dataset}/{model_name}_l{best_num_layers}_01/metrics.yaml'\n",
    "            with open(filename) as file:\n",
    "                metrics = yaml.safe_load(file)\n",
    "\n",
    "            test_metric_mean = metrics[f'test {metric_name} mean']\n",
    "            test_metric_std = metrics[f'test {metric_name} std']\n",
    "\n",
    "            string = f'{test_metric_mean * 100:.2f} \\u00B1 {test_metric_std * 100:.2f}'\n",
    "        \n",
    "        results.append(string)\n",
    "    \n",
    "    df.loc[model] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fe45657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roman-empire</th>\n",
       "      <th>amazon-ratings</th>\n",
       "      <th>minesweeper</th>\n",
       "      <th>tolokers</th>\n",
       "      <th>questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ResNet</th>\n",
       "      <td>65.88 ± 0.38</td>\n",
       "      <td>45.90 ± 0.52</td>\n",
       "      <td>50.89 ± 1.39</td>\n",
       "      <td>72.95 ± 1.06</td>\n",
       "      <td>70.34 ± 0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResNet+SGC</th>\n",
       "      <td>73.90 ± 0.51</td>\n",
       "      <td>50.66 ± 0.48</td>\n",
       "      <td>70.88 ± 0.90</td>\n",
       "      <td>80.70 ± 0.97</td>\n",
       "      <td>75.81 ± 0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResNet+adj</th>\n",
       "      <td>52.25 ± 0.40</td>\n",
       "      <td>51.83 ± 0.57</td>\n",
       "      <td>50.42 ± 0.83</td>\n",
       "      <td>78.78 ± 1.11</td>\n",
       "      <td>75.77 ± 1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCN</th>\n",
       "      <td>73.69 ± 0.74</td>\n",
       "      <td>48.70 ± 0.63</td>\n",
       "      <td>89.75 ± 0.52</td>\n",
       "      <td>83.64 ± 0.67</td>\n",
       "      <td>76.09 ± 1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAGE</th>\n",
       "      <td>85.74 ± 0.67</td>\n",
       "      <td>53.63 ± 0.39</td>\n",
       "      <td>93.51 ± 0.57</td>\n",
       "      <td>82.43 ± 0.44</td>\n",
       "      <td>76.44 ± 0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAT</th>\n",
       "      <td>80.87 ± 0.30</td>\n",
       "      <td>49.09 ± 0.63</td>\n",
       "      <td>92.01 ± 0.68</td>\n",
       "      <td>83.70 ± 0.47</td>\n",
       "      <td>77.43 ± 1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAT-sep</th>\n",
       "      <td>88.75 ± 0.41</td>\n",
       "      <td>52.70 ± 0.62</td>\n",
       "      <td>93.91 ± 0.35</td>\n",
       "      <td>83.78 ± 0.43</td>\n",
       "      <td>76.79 ± 0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GT</th>\n",
       "      <td>86.51 ± 0.73</td>\n",
       "      <td>51.17 ± 0.66</td>\n",
       "      <td>91.85 ± 0.76</td>\n",
       "      <td>83.23 ± 0.64</td>\n",
       "      <td>77.95 ± 0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GT-sep</th>\n",
       "      <td>87.32 ± 0.39</td>\n",
       "      <td>52.18 ± 0.80</td>\n",
       "      <td>92.29 ± 0.47</td>\n",
       "      <td>82.52 ± 0.92</td>\n",
       "      <td>78.05 ± 0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            roman-empire amazon-ratings   minesweeper      tolokers  \\\n",
       "ResNet      65.88 ± 0.38   45.90 ± 0.52  50.89 ± 1.39  72.95 ± 1.06   \n",
       "ResNet+SGC  73.90 ± 0.51   50.66 ± 0.48  70.88 ± 0.90  80.70 ± 0.97   \n",
       "ResNet+adj  52.25 ± 0.40   51.83 ± 0.57  50.42 ± 0.83  78.78 ± 1.11   \n",
       "GCN         73.69 ± 0.74   48.70 ± 0.63  89.75 ± 0.52  83.64 ± 0.67   \n",
       "SAGE        85.74 ± 0.67   53.63 ± 0.39  93.51 ± 0.57  82.43 ± 0.44   \n",
       "GAT         80.87 ± 0.30   49.09 ± 0.63  92.01 ± 0.68  83.70 ± 0.47   \n",
       "GAT-sep     88.75 ± 0.41   52.70 ± 0.62  93.91 ± 0.35  83.78 ± 0.43   \n",
       "GT          86.51 ± 0.73   51.17 ± 0.66  91.85 ± 0.76  83.23 ± 0.64   \n",
       "GT-sep      87.32 ± 0.39   52.18 ± 0.80  92.29 ± 0.47  82.52 ± 0.92   \n",
       "\n",
       "               questions  \n",
       "ResNet      70.34 ± 0.76  \n",
       "ResNet+SGC  75.81 ± 0.96  \n",
       "ResNet+adj  75.77 ± 1.24  \n",
       "GCN         76.09 ± 1.27  \n",
       "SAGE        76.44 ± 0.62  \n",
       "GAT         77.43 ± 1.20  \n",
       "GAT-sep     76.79 ± 0.71  \n",
       "GT          77.95 ± 0.68  \n",
       "GT-sep      78.05 ± 0.93  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835f9a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
